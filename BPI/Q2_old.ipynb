{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The csv file is large, please download it first then read from local files\n",
    "# if you insist in reading online, read it from the link above\n",
    "\n",
    "df_q2 = pd.read_csv('F:\\\\Competitions\\\\BPI\\\\data\\\\data_q2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bools = df_q2.select_dtypes(include='bool').columns.tolist()\n",
    "bool_to_int = df_q2.loc[:, bools].astype(int)\n",
    "df_q2 = df_q2.drop(columns=bools)\n",
    "df_q2 = pd.concat([df_q2, bool_to_int], axis=1)\n",
    "df_q2.columns = df_q2.columns.str.replace('\\s+', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalties = ['penalty_B3', 'penalty_B4', 'penalty_B5', 'penalty_B5F', 'penalty_B6', 'penalty_B16', 'penalty_BGK',\n",
    "             'penalty_BGKV', 'penalty_C16', 'penalty_JLP3', 'penalty_V5']\n",
    "attribs = ['number_parcels', 'area', 'young_farmer', 'small_farmer', 'redistribution']\n",
    "depts = df_q2['department'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q2_d_list = []\n",
    "for d in depts:\n",
    "    df_q2_d_list.append([d, df_q2.loc[df_q2['department'] == d].drop(columns='department')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(0, len(depts)):\n",
    "    df_q2_d = df_q2_d_list[k][1]\n",
    "    print(\"\\nFor department\", df_q2_d_list[k][0])\n",
    "#     X = df_q2_d[attribs]\n",
    "    for i in range(0, len(penalties)):\n",
    "#         y = df_q2_d[penalties[i]]\n",
    "\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "#         train = pd.concat([y_train, X_train], axis=1)\n",
    "        lm = smf.ols(formula= penalties[i] + ' ~ ' + ' + '.join(attribs),\n",
    "                       data=df_q2_d).fit()\n",
    "\n",
    "        if not lm.centered_tss:\n",
    "            print(penalties[i], ': TSS = 0, same value for all obs.')\n",
    "        elif lm.rsquared_adj > 0.5:\n",
    "            print(penalties[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.formula.api as smf\n",
    "# for k in range(0, len(depts)):\n",
    "#     df_q2_d = df_q2_d_list[k][1]\n",
    "#     print(\"\\nFor department\", df_q2_d_list[k][0])\n",
    "# #     X = df_q2_d[attribs]\n",
    "#     for i in range(0, len(penalties)):\n",
    "# #         y = df_q2_d[penalties[i]]\n",
    "\n",
    "# #         X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# #         train = pd.concat([y_train, X_train], axis=1)\n",
    "#         lm = smf.ols(formula= penalties[i] + ' ~ ' + ' + '.join(attribs),\n",
    "#                        data=df_q2_d).fit()\n",
    "\n",
    "#         if not lm.centered_tss:\n",
    "#             print(penalties[i], ': TSS = 0, same value for all obs.')\n",
    "#         elif lm.rsquared_adj > 0.5:\n",
    "#             print(penalties[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_q2_core = df_q2[attribs.append('severe')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_to_dummies = pd.get_dummies(df_q2_core['department'], prefix='dept').iloc[:, 1:]\n",
    "# df_q2_core = df_q2_core.drop(columns='department')\n",
    "# df_q2_core = pd.concat([df_q2_core, cat_to_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_columns', None):\n",
    "#     display(df_q2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# train = pd.concat([y_train, X_train], axis=1)\n",
    "# lm_0 = smf.ols(formula='severe ~ ' + ' + '.join(attribs),\n",
    "#                data=train).fit()\n",
    "# # lm_0.summary().tables[1]\n",
    "\n",
    "# lm_0_summary = pd.DataFrame({'coef':lm_0.params, 'pvalues': lm_0.pvalues})\n",
    "# lm_0_sig = lm_0_summary.where(lm_0.pvalues < 0.05).dropna()\n",
    "# print('The linear model including all trace attributes:\\n', lm_0_summary)\n",
    "# print('The significant coefficients:\\n', lm_0_sig)\n",
    "# print('\\nThe adjusted R-squared is',lm_0.rsquared_adj)\n",
    "\n",
    "# X_1 = [col for col in lm_0_sig.index.tolist() if col is not 'Intercept']\n",
    "# if not X_1:\n",
    "#     print('No significant regressor.')\n",
    "# else:\n",
    "#     lm_1 = smf.ols(formula='severe ~ ' + ' + '.join(X_1),\n",
    "#                data=train).fit()\n",
    "#     lm_1_summary = pd.DataFrame({'coef':lm_1.params, 'pvalues': lm_1.pvalues})\n",
    "#     print('\\nBuild a new linear model including only the significant coefficients from last model:\\n', lm_1_summary)\n",
    "#     print('\\nThe adjusted R-squared is', lm_1.rsquared_adj)\n",
    "#     print(\"It's better than the last one.\" if abs(lm_1.rsquared_adj)>abs(lm_1.rsquared_adj) else \"It's worse than the last one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for Q2, already done. The data is saved to:\n",
    "# https://raw.githubusercontent.com/Jeff-HOU/bpi.2018/master/data/data_q2.csv\n",
    "# ?token=AilEXVc0O5KlZviHuRGCT7A4Luhovbleks5a8BUjwA%3D%3D\n",
    "\n",
    "# df = pd.read_csv('F:\\\\Competitions\\\\BPI\\\\data\\\\data.csv')\n",
    "\n",
    "# # df_q2 = df[['case', 'event', 'year', 'startTime', 'applicant', 'department', 'doctype', 'subprocess', 'number_parcels',\n",
    "# #            'young farmer', 'small farmer', 'area', 'redistribution',\n",
    "# #            'penalty_B3', 'penalty_B4', 'penalty_B5', 'penalty_B5F', 'penalty_B6', 'penalty_B16', 'penalty_BGK', 'penalty_BGKV',\n",
    "# #            'penalty_C16', 'penalty_JLP3', 'penalty_V5',\n",
    "# #            'amount_applied0', 'amount_applied1', 'amount_applied2', 'amount_applied3',\n",
    "# #            'penalty_amount0', 'penalty_amount1', 'penalty_amount2', 'penalty_amount3',\n",
    "# #            'payment_actual0', 'payment_actual1', 'payment_actual2', 'payment_actual3', 'rejected']]\n",
    "\n",
    "# df_q2 = df[['case', 'department', 'number_parcels', 'young farmer', 'small farmer', 'area', 'redistribution',\n",
    "#            'penalty_B3', 'penalty_B4', 'penalty_B5', 'penalty_B5F', 'penalty_B6', 'penalty_B16', 'penalty_BGK', 'penalty_BGKV',\n",
    "#            'penalty_C16', 'penalty_JLP3', 'penalty_V5', 'rejected']]\n",
    "\n",
    "# df_q2 = df_q2.drop_duplicates(subset='case')\n",
    "# df_q2 = df_q2.fillna(0)\n",
    "# df_q2['severe'] = df_q2['penalty_B3'] | df_q2['penalty_B4'] | df_q2['penalty_B5'] | df_q2['penalty_B5F'] | df_q2['penalty_B6'] | df_q2['penalty_B16'] | df_q2['penalty_BGK'] | df_q2['penalty_BGKV'] | df_q2['penalty_C16'] | df_q2['penalty_JLP3'] | df_q2['penalty_V5']\n",
    "# df_q2.to_csv('F:\\\\Competitions\\\\BPI\\\\data\\\\data_q2.csv')\n",
    "\n",
    "# del df, df_q2\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
